\documentclass[10pt, a4paper,spanish]{article}

\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}

\usepackage[T1]{fontenc}

\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry}
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption}

\usepackage{float}

\usepackage{amsmath}

\usepackage[hidelinks]{hyperref}

\usepackage{graphicx}
\graphicspath{ {images/} }


\usepackage{minted}
\usepackage{float}
\RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}


\usepackage{titlesec}
\renewcommand\thesection{\Roman{section}}
\renewcommand\thesubsection{\Roman{subsection}}
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{}
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyhead[C]{ \today \ $\bullet$ Minería de Datos $\bullet$ Red de Hopfield}
\fancyfoot[RO]{\thepage}

%-------------------------------------------------------------------------------
%	TITLE SECTION
%-------------------------------------------------------------------------------

\title{\vspace{-15mm}\fontsize{24pt}{10pt}\selectfont\textbf{Red de Hopfield}}

\author{García Prado, Sergio}
\date{\today}

%-------------------------------------------------------------------------------

\begin{document}

	\maketitle

	\thispagestyle{fancy}


%-------------------------------------------------------------------------------
%	TEXT
%-------------------------------------------------------------------------------


  \section{Introducción}

    \paragraph{}
		Las redes de Hopfield son un tipo de redes neuronales recurrentes inicialmente desarrolladas por John Hopfield. Estas redes son usadas como sistemas de Memoria asociativa con unidades binarias y están diseñadas para converger a un mínimo local. A pesar de ello, la convergencia a alguno de los patrones almacenados no está garantizada.

		\paragraph{}
		Las unidades de las redes Hopfield son binarias, es decir, solo tienen dos valores posibles para sus estados (Esto se consigue a partir del uso de una función signo). El valor se determina si las unidades superan o no un determinado umbral. Los valores posibles pueden ser 1 ó -1,

		\paragraph{}
		Como caso de prueba, se ha realizado lo siguiente: Utilizando como modelo mental un cubo, se pretende introducir dos vértices opuestos del mismo, que serán utilizados como patrones a memorizar para después ser reconocidos a partir de pequeñas variaciones (resto de vértices). La red de Hopfield obtendrá como resultado el patrón más próximo a cada entrada.


	\section{Implementación}

		\paragraph{}
		La implementación del algoritmo, se han realizado en el lenguage Octave (debido a la facilidad y simplicidad que ofrece cuando se codifican expresiones matemáticas). A continuación se describen cada una de las partes en que se ha dividido la implementación: La primera de ellas consiste en un fichero \emph{main}, mientras que la segunda y la tercera forman propiamente el algoritmo, correspondiendose la primera fase al periodo de aprendizaje de patrones y la segunda a la clasificación de entradas.

		\begin{figure}[htpb!]
			\centering
			\inputminted{octave}{../src/main.m}
			\caption{Octave: main.m}
			\label{code:main}
		\end{figure}

		\begin{equation} \label{eq:1}
			\overline{X_{i}} = [x_{i1}, x_{i2}, ..., x_{ij}, ..., x_{in}], x_{ij} \in \{1,-1\} i \in (1,2,.., r),
		\end{equation}

		\begin{equation} \label{eq:2}
			\overline{P_{k}} = [p_{k1}, p_{k2}, ..., p_{kj}, ..., p_{kn}], p_{kj} \in \{1,-1\}, k \in (1,2,...s),
		\end{equation}

		\paragraph{}
		Tal y como se muestra en el código de la figura \ref{code:main}, primero definimos tanto la matriz que representa los  vectores que posteriormente serán utilizados como patrones como la que representa las entradas a clasificar. Estas matrices se pueden representar matemáticamente tal y como se indica en las fórmulas \ref{eq:1} y \ref{eq:2}.  Posteriormente se define la matriz $W$, encargada de almacenar los patrones, tal y como se explicará a continuación. Finalmente se calcula el resultado ($S$) (patrón más cercano a la entrada).

		\begin{figure}[htpb!]
			\centering
			\inputminted{octave}{../src/hopfield_learning.m}
			\caption{Octave: hopfield\_learning.m}
			\label{code:learning}
		\end{figure}

		\begin{equation} \label{eq:3}
			w_{ij} =
			\begin{cases}
				\sum_{k=1}^{s} p_{ki}p_{kj} 	& \forall i \neq j; 	\\
				0															& \forall i = j; 		\\
			\end{cases}
		\end{equation}

		\paragraph{}
		El proceso de rellenado de la matrix $W$, en la cual se almacenan los patrones enseñados en la fase de aprendizaje, se puede modelizar matemáticamente tal y como se indica en la ecuación \ref{eq:3}.

		\begin{figure}[htpb!]
			\centering
			\inputminted{octave}{../src/hopfield_working.m}
			\caption{Octave: hopfield\_working.m}
			\label{code:working}
		\end{figure}

		\paragraph{}
		El proceso de reconocimiento de patrones se realiza a partir de una ecuación de recurrencia, aplicando $S$ definida matemáticamente tal y como se indica en la ecuaci \ref{eq:4} (Notese que $u_{i}$ es una constante de ajuste, que en la implementación realizada toma el valor $0$, por lo que se ha obviado).

		\begin{equation} \label{eq:4}
		 	s_i(t) =
		 	\begin{cases}
      	x_i 																					& t = 0 		\\
      	sgn(\sum_{j=1}^{n} w_{ij}s_{j}(t-1) - u_{i}) 	& t \neq 0 	\\
   		\end{cases}
		\end{equation}

		\paragraph{}
		La función signo ($sgn(x)$) se define en la ecuación \ref{eq:5}. Como aclaración, para $x = 0$ esta función no toma ningún valor, por lo que se mantiene el valor de la iteración anterior.

		\begin{equation} \label{eq:5}
			sgn(x) =
			\begin{cases}
				+1 & x > 0 \\
				-1 & x < 0 \\
			\end{cases}
		\end{equation}

		\paragraph{}
		Este proceso se repite indefinidamente hasta que el resultado converge hacia un valor concreto. Dicho de otra manera, mientras se cumpla la condición de la equación \ref{eq:6}.

		\begin{equation} \label{eq:6}
			s_i(t+1) \neq s_i(t)
		\end{equation}

		\paragraph{}
		Una vez se llega a un valor constante, el proceso termina y el patrón debería haber sido reconocido. El método de Hopfield no asegura la convergencia hacia un patrón almacenado, sin embargo, esto si que sucede cuando los patrones enseñados en el periodo de aprendizaje son opuestos entre si.


	\section{Resultados}

		\paragraph{}
		Los resultados obtenidos para una ejecucción concreta con las entradas $x$ y $x_p$ se muestran en la figura \ref{results}. Tal y como se puede apreciar en el resultado (matriz $S$), los vectores de la entrada $X$ se aproximan al patrón almacenado más cercano en cada caso.

		\begin{figure}[htpb!]
			\centering
			\inputminted{bash}{../output.txt}
			\caption{Resultados obtenidos}
			\label{results}
		\end{figure}

\end{document}
